## 前程无忧70000条数据类岗位
>这一次通过爬虫爬取了前尘无忧所有的数据类的岗位，看看在今年的这种环境下，是否会有新的变数，在求职方面是否有新的问题出现
数据说明
第一份csv文件：

- 数据量多，可以用于练习清洗数据；

- 包含71034条招聘信息，其中有9列信息：岗位名称 、公司名称、 工作城市 、薪资、 发布详细 、公司类别 、公司规模、 行业、 岗位职责、

第二份csv文件：

- 经过清理出来，比较容易直观看，可以直接拿来分析可视化，无需清理数据；

- 包括12255条招聘信息，其中有10列信息：公司名 、岗位名、 工作地点、 工资水平 、发布日期、学历、 公司类型、 公司规模 、行业 、工作描述

数据来源
爬虫爬取：https://www.51job.com/

问题描述
1：哪个城市的数据类岗位最多；
2：什么行业的需求最多；
3：薪酬的分层如何；
4：学历要求的分布；


上代码咯
测试一下：

    Markdown 目录：
    [TOC]

    Markdown 标题：
    # 这是 H1
    ## 这是 H2
    ### 这是 H3

    Markdown 列表：
    - 列表项目
    1. 列表项目

    *斜体*或_斜体_
    **粗体**
    ***加粗斜体***
    ~~删除线~~

```
Markdown 插入链接：
[链接文字](链接网址 "标题")

Markdown 插入图片：
![alt text](/path/to/img.jpg "Title")

Markdown 插入代码块：
    ```python
    #!/usr/bin/python3
    print("Hello, World!");
    ```

Markdown 引用：
> 引用内容

Markdown 分割线：
---

Markdown 换行：
<br>

Markdown 段首缩进：
&ensp; or &#8194; 表示一个半角的空格
&emsp; or &#8195;  表示一个全角的空格
&emsp;&emsp; 两个全角的空格（用的比较多）
&nbsp; or &#160; 不断行的空白格  
```


### 首先导入数据清洗所需要的包
    import numpy as np
    import pandas as pd
    import re
    import jieba
    import warnings
    warnings.filterwarnings("ignore")
### 查看数据集
    df = pd.read_csv(r"filename", encoding="utf-8",header=None)
    df.sample(10)
    # 还记得 errors=ignore 吗，ignore 可以忽略非法字符（errors – 设置不同错误的处理方案。默认为 ‘strict’,意为编码错误引起一个代码产生UnicodeError错误，代表遇到非法字符时抛出异常。）
### 处理数据库 dataframe
    # 为数据框指定行索引
    df.index = range(len(df))
    # 为数据框指定列索引
    df.columns = ["岗位名","公司名","工作地点","工资","发布日期","经验与学历","公司类型","公司规模","行业","工作描述"]
    # 看一下数据长啥样了
    df.head(10)
### 数据去重
    # 数据去重，如果一个行业的公司名和发布的岗位名一致，我们认为是重复值，因此去除掉
    print("去重之前的记录数", df.shape)
    df.drop_duplicates(subset=["公司名","岗位名"], inplace=True) # inplace 表示原地删除
    print("去重之后的记录数", df.shape)
    
### 岗位名称的字段处理
#### 岗位名的探索
    df["岗位名"].value_counts()
    df["岗位名"] = df["岗位名"].apply(lambda x:x.lower())
    #df["岗位名"][0] = "数据岗（优秀应届毕业生）"
#### 筛选出我们想要分析的岗位
    target_job = ['算法', '开发', '分析', '工程师', '数据', '运营', '运维']
    # 注意 `count()` 函数的用法，如果某个岗位名求和大于0，就**证明包含了这些关键字字眼**，否则就是不包含。
    # [df["岗位名"][0].count(i) for i in target_job] #结果是[0,0,0,0,1,0,0]
    index = [df["岗位名"].str.count(i) for i in target_job]
    index = np.array(index).sum(axis=0) > 0 #每一个岗位均有一个7元素的列表，计算该列表元素之和，挑选出大于0的数据赋值为True，作为索引筛选数据
    job_info = df[index]
    job_info.shape
    job_info.head(10)
#### 将岗位名称标准化
    # 将岗位名称标准化：目前岗位太多太杂，需要统一
    job_list = ['数据分析', "数据统计","数据专员",'数据挖掘', '算法', '大数据',
            '开发工程师', '运营', '软件工程', '前端开发',
            '深度学习', 'ai', '数据库', '数据库', '数据产品',
            '客服', 'java', '.net', 'andrio', '人工智能', 'c++',
            '数据管理',"测试","运维"]
    job_list = np.array(job_list) #将列表转换为 数组
    job_list
    
    # 定义 rename 函数
    def rename(x=None,name_list=job_list):
        index = [i in x for i in name_list] # 判断岗位名称中是否有标准化名字
        if sum(index) > 0:
            return name_list[index][0] # 有点难理解，拿逻辑值去取值
        else:
            return x
    job_info["岗位名"] = job_info["岗位名"].apply(rename)
    job_info["岗位名"].value_counts()
    # 生成 岗位名 数量，可用于分析的数据集
    # 将数据统计、数据专员、数据分析 统一归为数据分析
    job_info["岗位名"] = job_info["岗位名"].apply(lambda x:re.sub("数据专员","数据分析",x))
    job_info["岗位名"] = job_info["岗位名"].apply(lambda x:re.sub("数据统计","数据分析",x))
    job_s = job_info["岗位名"].value_counts()[:20] 岗位前20
    job_s # 展示数据
    
#### 绘制岗位柱状图
    # 条形图
    from pyecharts.charts import Pie, Funnel,Map,Page,Bar,Sankey
    from pyecharts import options as opts
    from pyecharts.globals import SymbolType
    bar1 = Bar(init_opts=opts.InitOpts(width='700px',height='1000px'),)
    bar1set_series_opts(label_opts=opts.Labelopts(position='right'))
    bar1.reversal_axis()
    bar1.render_notebook()
    
    
### 工资字段处理
说明：工资数据给出的一般是一个范围，数据也很不标准，例如“千/月、万/月、万/年”等。对其统一进行处理，去数据范围的平均值
兼职的工资 以 天 结尾，直接删除
#### 转化工资
    job_info["工资"].str[-1].value_counts()
    job_info["工资"].str[-3].value_counts()
    
    index1 = job_info["工资"].str[-1].isin(["年","月"])
    index2 = job_info["工资"].str[-3].isin(["万","千"])
    job_info = job_info[index1 & index2]
    # 这种都是用逻辑值当索引
    
    def get_money_max_min(x):
        try:
            if x[-3] == '万':
                z = [float(i)*10000 for i in re.findall("[0-9]+\.?[0-9]*",x)]
            elif x[-3] == '千':
                z = [float(i)*1000 for i in re.findall("[0-9]+\.?[0-9]*",x)]
            if x[-1] == '年':
                z = [i/12 for i in z]
            return z
        except:
            return x
    salary = job_info["工资"].apply(get_money_max_min)
    # salary 数据类型为应该 Series吧，返回的 z 同样,仅剩数字
    # [8000.0, 10000.0]
    job_info["最低工资"] = salary.str[0]
    job_info["最高工资"] = salary.str[1]
    job_info["工资水平"] = job_info[["最低工资","最高工资"]].mean(axis=1) #axis=0表示纵轴的方向，axis=1表示横轴的方向
    job_info["工资水平"] = round(jon_info["工资水平"],0) #round() 方法返回浮点数x的四舍五入值，`round(x[,n])`，n表示保留小数位数
    job_info["工资水平"]
    
#### 工资的分布
    # 划分层级
    def transform_gz(x):
        if x <= 5000.0:
            return '低于5千/月'
        elif x <= 8000.0:
            return '5千~8千/月'
        elif x <= 10000.0:
            return '8千~1万/月'
        elif x <= 15000.0:
            return '1万~1万5/月'
        else:
            return '1万5以上/月'
     # 新增一列 分级
     job_info["分级"] = job_info["工资水平"].apply(lambda x:transform_gz(x))
     # 工资分布水平 gz_num
     gz_num = job_info["分级"].value_counts()
     print(gz_num)
    > 5千~8千/月     4570
    > 1万~1万5/月    2834
    > 1万5以上/月     1885
    > 8千~1万/月     1873
    > 低于5千/月      1093
    
### 绘制饼图
    data_pair = [list(z) for z in zip(gz_num.index.to_list(),gz_num.values.to_list())]
    # 绘制饼图\环形图
    pie1 = Pie()
    pie1.add('',data_pair,radius=['35%','60%'],rosetype='radius')
    pie1.set_global_opts(title_opts=opts.TitleOPts(title="工资分布"),
        legend_opts=opts.lengendOpts(orient='vertical',pos_top='15%',pos_left='2%'))
    pie1.set_series_opts(label_opts=opts.LabelOpts(formatter="{b}:{d}%"))
    pie1.set_colors(['#EF9050', '#3B7BA9', '#6FB27C', '#FFAF34', '#D8BFD8', '#00BFFF'])
    pie1.render_notebook()
