## 前程无忧70000条数据类岗位
>这一次通过爬虫爬取了前尘无忧所有的数据类的岗位，看看在今年的这种环境下，是否会有新的变数，在求职方面是否有新的问题出现
数据说明
第一份csv文件：

- 数据量多，可以用于练习清洗数据；

- 包含71034条招聘信息，其中有9列信息：岗位名称 、公司名称、 工作城市 、薪资、 发布详细 、公司类别 、公司规模、 行业、 岗位职责、

第二份csv文件：

- 经过清理出来，比较容易直观看，可以直接拿来分析可视化，无需清理数据；

- 包括12255条招聘信息，其中有10列信息：公司名 、岗位名、 工作地点、 工资水平 、发布日期、学历、 公司类型、 公司规模 、行业 、工作描述

数据来源
爬虫爬取：https://www.51job.com/

问题描述
1：哪个城市的数据类岗位最多；
2：什么行业的需求最多；
3：薪酬的分层如何；
4：学历要求的分布；


上代码咯
测试一下：
    Markdown 目录：
    [TOC]

    Markdown 标题：
    # 这是 H1
    ## 这是 H2
    ### 这是 H3

    Markdown 列表：
    - 列表项目
    1. 列表项目

    *斜体*或_斜体_
    **粗体**
    ***加粗斜体***
    ~~删除线~~

```
Markdown 插入链接：
[链接文字](链接网址 "标题")

Markdown 插入图片：
![alt text](/path/to/img.jpg "Title")

Markdown 插入代码块：
    ```python
    #!/usr/bin/python3
    print("Hello, World!");
    ```

Markdown 引用：
> 引用内容

Markdown 分割线：
---

Markdown 换行：
<br>

Markdown 段首缩进：
&ensp; or &#8194; 表示一个半角的空格
&emsp; or &#8195;  表示一个全角的空格
&emsp;&emsp; 两个全角的空格（用的比较多）
&nbsp; or &#160; 不断行的空白格  
```


### 首先导入数据清洗所需要的包
    import numpy as np
    import pandas as pd
    import re
    import jieba
    import warnings
    warnings.filterwarnings("ignore")
### 查看数据集
    df = pd.read_csv(r"filename", encoding="utf-8",header=None)
    df.sample(10)
    # 还记得 errors=ignore 吗，ignore 可以忽略非法字符（errors – 设置不同错误的处理方案。默认为 ‘strict’,意为编码错误引起一个代码产生UnicodeError错误，代表遇到非法字符时抛出异常。）
### 处理数据库 dataframe
    # 为数据框指定行索引
    df.index = range(len(df))
    # 为数据框指定列索引
    df.columns = ["岗位名","公司名","工作地点","工资","发布日期","经验与学历","公司类型","公司规模","行业","工作描述"]
    # 看一下数据长啥样了
    df.head(10)
### 数据去重
    # 数据去重，如果一个行业的公司名和发布的岗位名一致，我们认为是重复值，因此去除掉
    print("去重之前的记录数", df.shape)
    df.drop_duplicates(subset=["公司名","岗位名"], inplace=True) # inplace 表示原地删除
    print("去重之后的记录数", df.shape)
    
### 岗位名称的字段处理
#### 岗位名的探索
    df["岗位名"].value_counts()
    df["岗位名"] = df["岗位名"].apply(lambda x:x.lower())
    #df["岗位名"][0] = "数据岗（优秀应届毕业生）"
#### 筛选出我们想要分析的岗位
    target_job = ['算法', '开发', '分析', '工程师', '数据', '运营', '运维']
    # 注意 `count()` 函数的用法，如果某个岗位名求和大于0，就**证明包含了这些关键字字眼**，否则就是不包含。
    # [df["岗位名"][0].count(i) for i in target_job] #结果是[0,0,0,0,1,0,0]
    index = [df["岗位名"].str.count(i) for i in target_job]
    index = np.array(index).sum(axis=0) > 0 #每一个岗位均有一个7元素的列表，计算该列表元素之和，挑选出大于0的数据赋值为True，作为索引筛选数据
    job_info = df[index]
    job_info.shape
    job_info.head(10)
#### 将岗位名称标准化
    # 将岗位名称标准化：目前岗位太多太杂，需要统一
    job_list = ['数据分析', "数据统计","数据专员",'数据挖掘', '算法', '大数据',
            '开发工程师', '运营', '软件工程', '前端开发',
            '深度学习', 'ai', '数据库', '数据库', '数据产品',
            '客服', 'java', '.net', 'andrio', '人工智能', 'c++',
            '数据管理',"测试","运维"]
    job_list = np.array(job_list) #将列表转换为 数组
    job_list
    
    # 定义 rename 函数
    def rename(x=None,name_list=job_list):
        index = [i in x for i in name_list] # 判断岗位名称中是否有标准化名字
        if sum(index) > 0:
            return name_list[index][0] # 有点难理解，拿逻辑值去取值
        else:
            return x
